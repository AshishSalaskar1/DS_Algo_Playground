{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Great comparison: https://www.youtube.com/watch?v=AZnGRKFUU0c\n",
    "- Great Code comparison: https://builtin.com/data-science/multithreading-multiprocessing\n",
    "- Good lock based examples: https://www.turing.com/kb/python-multiprocessing-vs-multithreading\n",
    "- OS Level metrics (Best real-world examples): https://www.youtube.com/watch?v=BhnB45Rf3dg\n",
    "\n",
    "- Some Myths: https://medium.com/contentsquare-engineering-blog/multithreading-vs-multiprocessing-in-python-ece023ad55a\n",
    "- ThreadPoolExecutor: https://www.digitalocean.com/community/tutorials/how-to-use-threadpoolexecutor-in-python-3\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiThreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best for I/O tasks, Lightweight and easy to spawn\n",
    "- Its Concurrent but not parallel\n",
    "- Every 15s or any I/O operation comes -> the threads being executed are changed\n",
    "- Since I/O anyways need some time in between, at that time other threads can run -> **Hence great for I/O Tasks**\n",
    "- You can share variables -> but need to use locks ( in case of concurrent updates )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_res = []\n",
    "def api_call(url, retry_duration, lock):\n",
    "    global res\n",
    "\n",
    "    with lock: # lock.acquire() -> lock.release()\n",
    "        # hit the api\n",
    "        global_res.append({\"res\": url+str(retry_duration)})\n",
    "    \n",
    "    return {\"res\": url+str(retry_duration)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'res': 'https://google.com10'}, {'res': 'https://facebook.com5'}, {'res': 'https://reddit.com5'}, {'res': 'https://instagram.com15'}]\n"
     ]
    }
   ],
   "source": [
    "lock = threading.Lock()\n",
    "thread1 = threading.Thread(target=api_call, args=(\"https://google.com\", 10, lock))\n",
    "thread2 = threading.Thread(target=api_call, args=(\"https://facebook.com\", 5, lock))\n",
    "thread3 = threading.Thread(target=api_call, args=(\"https://reddit.com\", 5, lock))\n",
    "thread4 = threading.Thread(target=api_call, args=(\"https://instagram.com\", 15, lock))\n",
    "\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "\n",
    "thread1.join()\n",
    "thread2.join()\n",
    "thread3.join()\n",
    "thread4.join()\n",
    "\n",
    "print(global_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'res': 'https://reddit.com10'}, {'res': 'https://facebook.com10'}, {'res': 'https://google.com10'}, {'res': 'https://instagram.com10'}]\n",
      "[{'res': 'https://google.com10'}, {'res': 'https://facebook.com10'}, {'res': 'https://reddit.com10'}, {'res': 'https://instagram.com10'}]\n"
     ]
    }
   ],
   "source": [
    "global_res = []\n",
    "with ThreadPoolExecutor(3) as executor:\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    urls = [\"https://google.com\",\"https://facebook.com\",\"https://reddit.com\",\"https://instagram.com\"]\n",
    "\n",
    "    # submit tasks to thread pool\n",
    "    futures = [executor.submit(api_call, url, 10, lock) for url in urls] \n",
    "    # wait for all tasks to complete\n",
    "    results = [future.result() for future in as_completed(futures)]\n",
    "\n",
    "    print(results)\n",
    "    print(global_res)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultiProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best for CPU based tasks, Heavy to spawn since each needs its own memory space\n",
    "- Each process has its own Memory space -> NO variable sharing\n",
    "- Even if you share, like in below example -> each process has its own global variable which will be empty. Wont matter to you\n",
    "- **Share variables?** -> Use `multiprocessing.manager`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_res = []\n",
    "def api_call(url, retry_duration):\n",
    "    global res\n",
    "\n",
    "    # with lock: # lock.acquire() -> lock.release()\n",
    "        # hit the api\n",
    "    global_res.append({\"res\": url+str(retry_duration)})\n",
    "    \n",
    "    return {\"res\": url+str(retry_duration)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "process1 = multiprocessing.Process(target=api_call, args=(\"https://google.com\", 10))\n",
    "process2 = multiprocessing.Process(target=api_call, args=(\"https://facebook.com\", 5))\n",
    "process3 = multiprocessing.Process(target=api_call, args=(\"https://reddit.com\", 5))\n",
    "process4 = multiprocessing.Process(target=api_call, args=(\"https://instagram.com\", 15))\n",
    "\n",
    "process1.start()\n",
    "process2.start()\n",
    "process3.start()\n",
    "process4.start()\n",
    "\n",
    "process1.join()\n",
    "process2.join()\n",
    "process3.join()\n",
    "process4.join()\n",
    "\n",
    "print(global_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultiProcessing Manager / ProcessPool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **IMP**: All code that runs in MultiProcessing mode, needs to be under `if __name__ == '__main__':`\n",
    "- You can import files, but eventually its parent must be under a main\n",
    "- https://realpython.com/if-name-main-python/\n",
    "\n",
    "The if __name__ == '__main__': guard is required in Python when using multiprocessing (or ProcessPoolExecutor, which is based on multiprocessing). It ensures that the code that creates and starts processes runs only in the main process, preventing unintended recursive execution when a new process is spawned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limitations of Jupyter for multiprocessing**\n",
    "- Jupyter Notebooks do not handle multiprocessing well because of how they manage process spawning.\n",
    "- Use if `__name__ == \"__main__\":` in standalone Python scripts to avoid recursive execution when working with multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task failed with exception: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Task failed with exception: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Task failed with exception: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Task failed with exception: A process in the process pool was terminated abruptly while the future was running or pending.\n",
      "Results: []\n"
     ]
    }
   ],
   "source": [
    "def api_call(url, retry_duration):\n",
    "    return {\"res\": url+str(retry_duration)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    urls = [\n",
    "        \"https://google.com\",\n",
    "        \"https://facebook.com\",\n",
    "        \"https://reddit.com\",\n",
    "        \"https://instagram.com\",\n",
    "    ]\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=3) as executor:\n",
    "        # Submit tasks to the process pool\n",
    "        futures = [executor.submit(api_call, url, 10) for url in urls]\n",
    "\n",
    "        # Collect and print results as tasks complete\n",
    "        results = []\n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                results.append(future.result())\n",
    "            except Exception as e:\n",
    "                print(f\"Task failed with exception: {e}\")\n",
    "\n",
    "    print(\"Results:\", results)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using `multiprocessing.manager`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://medium.com/@amitkumaryadav27/multiprocessing-and-multiprocessing-manager-to-share-an-object-with-processes-in-python-946b88552b84\n",
    "- https://superfastpython.com/multiprocessing-manager-example/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(api_call_and_store, url, \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls]\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;66;03m# Collect results\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m as_completed(futures)]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print results\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResults (from return values):\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n",
      "File \u001b[1;32mc:\\Users\\ashis\\miniconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32mc:\\Users\\ashis\\miniconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "from multiprocessing import Manager\n",
    "\n",
    "def api_call(url, retry_duration):\n",
    "    # Simulate hitting an API and returning a result\n",
    "    return {\"res\": url + str(retry_duration)}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with Manager() as manager:  # Manager for shared data structures\n",
    "        global_res = manager.list()  # Shared list for results\n",
    "\n",
    "        # Function to update the shared list\n",
    "        def api_call_and_store(url, retry_duration):\n",
    "            result = api_call(url, retry_duration)\n",
    "            global_res.append(result)\n",
    "            return result\n",
    "\n",
    "        urls = [\"https://google.com\", \"https://facebook.com\", \"https://reddit.com\", \"https://instagram.com\"]\n",
    "\n",
    "        with ProcessPoolExecutor(3) as executor:\n",
    "            # Submit tasks to process pool\n",
    "            futures = [executor.submit(api_call_and_store, url, 10) for url in urls]\n",
    "            \n",
    "            # Collect results\n",
    "            results = [future.result() for future in as_completed(futures)]\n",
    "\n",
    "        # Print results\n",
    "        print(\"Results (from return values):\", results)\n",
    "        print(\"Global Results (shared list):\", list(global_res))  # Convert shared list to regular list for display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Singleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseConnection:\n",
    "    _conn = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_connection():\n",
    "        if DatabaseConnection._conn is None:\n",
    "            DatabaseConnection._conn = f\"SOME CONNECTION - {random.randint(1,10)}\"\n",
    "        return DatabaseConnection._conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SOME CONNECTION - 4\n",
      "SOME CONNECTION - 4\n",
      "SOME CONNECTION - 4\n",
      "SOME CONNECTION - 4\n",
      "SOME CONNECTION - 4\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    print(DatabaseConnection.get_connection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunNumbers:\n",
    "    def __init__(self, n=10):\n",
    "        self.counter = 0\n",
    "        self.n = n\n",
    "    \n",
    "    def print_nums(self):\n",
    "        with self.lock:\n",
    "            print(f\"Printing Number {self.counter} by thread {threading.current_thread().name}\")\n",
    "            self.counter += 1\n",
    "    \n",
    "    def run(self):\n",
    "        self.lock = threading.Lock();\n",
    "        t1 = threading.Thread(target=self.print_nums, name=\"THREAD 3\")\n",
    "        t2 = threading.Thread(target=self.print_nums, name=\"THREAD 2\")\n",
    "        t3 = threading.Thread(target=self.print_nums, name=\"THREAD 1\")\n",
    "\n",
    "        t1.start()\n",
    "        t2.start()\n",
    "        t3.start()\n",
    "\n",
    "        t1.join()\n",
    "        t2.join()\n",
    "        t3.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Number 0 by thread THREAD 3\n",
      "Printing Number 1 by thread THREAD 2\n",
      "Printing Number 2 by thread THREAD 1\n"
     ]
    }
   ],
   "source": [
    "run = RunNumbers()\n",
    "run.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NumberPrinter:\n",
    "    def __init__(self, n, num_threads):\n",
    "        self.n = n\n",
    "        self.num_threads = num_threads\n",
    "        self.lock = threading.Lock()\n",
    "        self.condition = threading.Condition(self.lock)\n",
    "        self.current = 1\n",
    "        self.turn = 0  # Keeps track of which thread's turn it is\n",
    "\n",
    "    def print_number(self, thread_id):\n",
    "        while True:\n",
    "            with self.condition:\n",
    "                while self.current <= self.n and self.turn != thread_id:\n",
    "                    self.condition.wait()\n",
    "                \n",
    "                if self.current > self.n:\n",
    "                    break\n",
    "                \n",
    "                print(f\"Thread-{thread_id}: {self.current}\")\n",
    "                self.current += 1\n",
    "                self.turn = (self.turn + 1) % self.num_threads\n",
    "                self.condition.notify_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread-0: 1\n",
      "Thread-1: 2\n",
      "Thread-2: 3\n",
      "Thread-0: 4\n",
      "Thread-1: 5\n",
      "Thread-2: 6\n",
      "Thread-0: 7\n",
      "Thread-1: 8\n",
      "Thread-2: 9\n",
      "Thread-0: 10\n",
      "Thread-1: 11\n",
      "Thread-2: 12\n",
      "Thread-0: 13\n",
      "Thread-1: 14\n",
      "Thread-2: 15\n"
     ]
    }
   ],
   "source": [
    "n = 15\n",
    "num_threads = 3\n",
    "printer = NumberPrinter(n, num_threads)\n",
    "\n",
    "threads = []\n",
    "for i in range(num_threads):\n",
    "    thread = threading.Thread(target=printer.print_number, args=(i,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFR_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-5NNHZiz8-R"
      },
      "source": [
        "# 1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
        "# 2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
        "# 3.  You cannot use DropOut layers.\n",
        "# 4.  You MUST use Image Augmentation Techniques.\n",
        "# 5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
        "# 6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
        "# 7.  You cannot use test images for training the model.\n",
        "# 8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
        "# 9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
        "# 10. You cannot have more than 1 Million parameters in total\n",
        "# 11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
        "# 12. You can use any optimization algorithm you need. \n",
        "# 13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pguNqfCrz88N"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Concatenate, SeparableConv2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjDDik2lz86T"
      },
      "source": [
        "\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 10\n",
        "l = 12\n",
        "num_filter = 18\n",
        "compression = 1\n",
        "dropout_rate = 0"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HGCnhUhz813"
      },
      "source": [
        "# Load CIFAR10 Data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
        "\n",
        "# convert to one hot encoing \n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxWlRaP4zQe6",
        "outputId": "7b0464ce-c08d-4da4-e9c8-224224340621"
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255  \n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbbsmcdM7Xia"
      },
      "source": [
        "# Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRgP1LFZ7Zcm"
      },
      "source": [
        "aug = ImageDataGenerator(shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         height_shift_range=0.1,\n",
        "                         horizontal_flip=True) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBIbcvA07J09"
      },
      "source": [
        "# Model Building and Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5brUjbdzTVA"
      },
      "source": [
        "# Dense Block\n",
        "def denseblock(input, num_filter = 48, dropout_rate = 0.0):\n",
        "    global compression\n",
        "    temp = input\n",
        "    for _ in range(l): \n",
        "        BatchNorm = layers.BatchNormalization()(temp)\n",
        "        relu = layers.Activation('relu')(BatchNorm)\n",
        "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
        "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
        "        temp = concat\n",
        "        \n",
        "    return temp\n",
        "\n",
        "## transition Blosck\n",
        "def transition(input, num_filter = 48, dropout_rate = 0.0):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
        "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
        "    return avg\n",
        "\n",
        "#output layer\n",
        "def output_layer(input):\n",
        "    global compression\n",
        "    BatchNorm = layers.BatchNormalization()(input)\n",
        "    relu = layers.Activation('relu')(BatchNorm)\n",
        "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
        "    flat = layers.Flatten()(AvgPooling)\n",
        "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
        "    return output"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0o9PhY_07Rg"
      },
      "source": [
        "input = layers.Input(shape=(img_height, img_width, channel,))\n",
        "First_Conv2D = layers.Conv2D(num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
        "\n",
        "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
        "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
        "\n",
        "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
        "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
        "\n",
        "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
        "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
        "\n",
        "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
        "output = output_layer(Last_Block)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qsDXXHg08NI"
      },
      "source": [
        "model = Model(inputs=[input], outputs=[output])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZtuPKU5Myor",
        "outputId": "78b88890-a09b-438d-c403-0270420c51d4"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 32, 32, 18)   486         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, 32, 32, 18)   72          conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, 32, 32, 18)   0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 32, 32, 18)   2916        activation_312[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_288 (Concatenate)   (None, 32, 32, 36)   0           conv2d_312[0][0]                 \n",
            "                                                                 conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, 32, 32, 36)   144         concatenate_288[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, 32, 32, 36)   0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 32, 32, 18)   5832        activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_289 (Concatenate)   (None, 32, 32, 54)   0           concatenate_288[0][0]            \n",
            "                                                                 conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, 32, 32, 54)   216         concatenate_289[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, 32, 32, 54)   0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 32, 32, 18)   8748        activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_290 (Concatenate)   (None, 32, 32, 72)   0           concatenate_289[0][0]            \n",
            "                                                                 conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, 32, 32, 72)   288         concatenate_290[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, 32, 32, 72)   0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 32, 32, 18)   11664       activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_291 (Concatenate)   (None, 32, 32, 90)   0           concatenate_290[0][0]            \n",
            "                                                                 conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, 32, 32, 90)   360         concatenate_291[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, 32, 32, 90)   0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 32, 32, 18)   14580       activation_316[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_292 (Concatenate)   (None, 32, 32, 108)  0           concatenate_291[0][0]            \n",
            "                                                                 conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, 32, 32, 108)  432         concatenate_292[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, 32, 32, 108)  0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 32, 32, 18)   17496       activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_293 (Concatenate)   (None, 32, 32, 126)  0           concatenate_292[0][0]            \n",
            "                                                                 conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, 32, 32, 126)  504         concatenate_293[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, 32, 32, 126)  0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 32, 32, 18)   20412       activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_294 (Concatenate)   (None, 32, 32, 144)  0           concatenate_293[0][0]            \n",
            "                                                                 conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, 32, 32, 144)  576         concatenate_294[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, 32, 32, 144)  0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 32, 32, 18)   23328       activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_295 (Concatenate)   (None, 32, 32, 162)  0           concatenate_294[0][0]            \n",
            "                                                                 conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, 32, 32, 162)  648         concatenate_295[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, 32, 32, 162)  0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 32, 32, 18)   26244       activation_320[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_296 (Concatenate)   (None, 32, 32, 180)  0           concatenate_295[0][0]            \n",
            "                                                                 conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, 32, 32, 180)  720         concatenate_296[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, 32, 32, 180)  0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 32, 32, 18)   29160       activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_297 (Concatenate)   (None, 32, 32, 198)  0           concatenate_296[0][0]            \n",
            "                                                                 conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, 32, 32, 198)  792         concatenate_297[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, 32, 32, 198)  0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 32, 32, 18)   32076       activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_298 (Concatenate)   (None, 32, 32, 216)  0           concatenate_297[0][0]            \n",
            "                                                                 conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, 32, 32, 216)  864         concatenate_298[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, 32, 32, 216)  0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 32, 32, 18)   34992       activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_299 (Concatenate)   (None, 32, 32, 234)  0           concatenate_298[0][0]            \n",
            "                                                                 conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, 32, 32, 234)  936         concatenate_299[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, 32, 32, 234)  0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 32, 32, 18)   4212        activation_324[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_24 (AveragePo (None, 16, 16, 18)   0           conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, 16, 16, 18)   72          average_pooling2d_24[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, 16, 16, 18)   0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 16, 16, 18)   2916        activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_300 (Concatenate)   (None, 16, 16, 36)   0           average_pooling2d_24[0][0]       \n",
            "                                                                 conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, 16, 16, 36)   144         concatenate_300[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, 16, 16, 36)   0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 16, 16, 18)   5832        activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_301 (Concatenate)   (None, 16, 16, 54)   0           concatenate_300[0][0]            \n",
            "                                                                 conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, 16, 16, 54)   216         concatenate_301[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, 16, 16, 54)   0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 16, 16, 18)   8748        activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_302 (Concatenate)   (None, 16, 16, 72)   0           concatenate_301[0][0]            \n",
            "                                                                 conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, 16, 16, 72)   288         concatenate_302[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, 16, 16, 72)   0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 16, 16, 18)   11664       activation_328[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_303 (Concatenate)   (None, 16, 16, 90)   0           concatenate_302[0][0]            \n",
            "                                                                 conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, 16, 16, 90)   360         concatenate_303[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, 16, 16, 90)   0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 16, 16, 18)   14580       activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_304 (Concatenate)   (None, 16, 16, 108)  0           concatenate_303[0][0]            \n",
            "                                                                 conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, 16, 16, 108)  432         concatenate_304[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, 16, 16, 108)  0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 16, 16, 18)   17496       activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_305 (Concatenate)   (None, 16, 16, 126)  0           concatenate_304[0][0]            \n",
            "                                                                 conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, 16, 16, 126)  504         concatenate_305[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, 16, 16, 126)  0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 16, 16, 18)   20412       activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_306 (Concatenate)   (None, 16, 16, 144)  0           concatenate_305[0][0]            \n",
            "                                                                 conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, 16, 16, 144)  576         concatenate_306[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, 16, 16, 144)  0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 16, 16, 18)   23328       activation_332[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_307 (Concatenate)   (None, 16, 16, 162)  0           concatenate_306[0][0]            \n",
            "                                                                 conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, 16, 16, 162)  648         concatenate_307[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, 16, 16, 162)  0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 16, 16, 18)   26244       activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_308 (Concatenate)   (None, 16, 16, 180)  0           concatenate_307[0][0]            \n",
            "                                                                 conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, 16, 16, 180)  720         concatenate_308[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, 16, 16, 180)  0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 16, 16, 18)   29160       activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_309 (Concatenate)   (None, 16, 16, 198)  0           concatenate_308[0][0]            \n",
            "                                                                 conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, 16, 16, 198)  792         concatenate_309[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, 16, 16, 198)  0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, 16, 16, 18)   32076       activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_310 (Concatenate)   (None, 16, 16, 216)  0           concatenate_309[0][0]            \n",
            "                                                                 conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, 16, 16, 216)  864         concatenate_310[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, 16, 16, 216)  0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, 16, 16, 18)   34992       activation_336[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_311 (Concatenate)   (None, 16, 16, 234)  0           concatenate_310[0][0]            \n",
            "                                                                 conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, 16, 16, 234)  936         concatenate_311[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, 16, 16, 234)  0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, 16, 16, 18)   4212        activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_25 (AveragePo (None, 8, 8, 18)     0           conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, 8, 8, 18)     72          average_pooling2d_25[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, 8, 8, 18)     0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, 8, 8, 18)     2916        activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_312 (Concatenate)   (None, 8, 8, 36)     0           average_pooling2d_25[0][0]       \n",
            "                                                                 conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, 8, 8, 36)     144         concatenate_312[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, 8, 8, 36)     0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, 8, 8, 18)     5832        activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_313 (Concatenate)   (None, 8, 8, 54)     0           concatenate_312[0][0]            \n",
            "                                                                 conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, 8, 8, 54)     216         concatenate_313[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, 8, 8, 54)     0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, 8, 8, 18)     8748        activation_340[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_314 (Concatenate)   (None, 8, 8, 72)     0           concatenate_313[0][0]            \n",
            "                                                                 conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, 8, 8, 72)     288         concatenate_314[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, 8, 8, 72)     0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, 8, 8, 18)     11664       activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_315 (Concatenate)   (None, 8, 8, 90)     0           concatenate_314[0][0]            \n",
            "                                                                 conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, 8, 8, 90)     360         concatenate_315[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, 8, 8, 90)     0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, 8, 8, 18)     14580       activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_316 (Concatenate)   (None, 8, 8, 108)    0           concatenate_315[0][0]            \n",
            "                                                                 conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, 8, 8, 108)    432         concatenate_316[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, 8, 8, 108)    0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, 8, 8, 18)     17496       activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_317 (Concatenate)   (None, 8, 8, 126)    0           concatenate_316[0][0]            \n",
            "                                                                 conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, 8, 8, 126)    504         concatenate_317[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, 8, 8, 126)    0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, 8, 8, 18)     20412       activation_344[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_318 (Concatenate)   (None, 8, 8, 144)    0           concatenate_317[0][0]            \n",
            "                                                                 conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, 8, 8, 144)    576         concatenate_318[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, 8, 8, 144)    0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, 8, 8, 18)     23328       activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_319 (Concatenate)   (None, 8, 8, 162)    0           concatenate_318[0][0]            \n",
            "                                                                 conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, 8, 8, 162)    648         concatenate_319[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, 8, 8, 162)    0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, 8, 8, 18)     26244       activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_320 (Concatenate)   (None, 8, 8, 180)    0           concatenate_319[0][0]            \n",
            "                                                                 conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, 8, 8, 180)    720         concatenate_320[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, 8, 8, 180)    0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, 8, 8, 18)     29160       activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_321 (Concatenate)   (None, 8, 8, 198)    0           concatenate_320[0][0]            \n",
            "                                                                 conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, 8, 8, 198)    792         concatenate_321[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, 8, 8, 198)    0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, 8, 8, 18)     32076       activation_348[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_322 (Concatenate)   (None, 8, 8, 216)    0           concatenate_321[0][0]            \n",
            "                                                                 conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, 8, 8, 216)    864         concatenate_322[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, 8, 8, 216)    0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, 8, 8, 18)     34992       activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_323 (Concatenate)   (None, 8, 8, 234)    0           concatenate_322[0][0]            \n",
            "                                                                 conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, 8, 8, 234)    936         concatenate_323[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, 8, 8, 234)    0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, 8, 8, 18)     4212        activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_26 (AveragePo (None, 4, 4, 18)     0           conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, 4, 4, 18)     72          average_pooling2d_26[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, 4, 4, 18)     0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, 4, 4, 18)     2916        activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_324 (Concatenate)   (None, 4, 4, 36)     0           average_pooling2d_26[0][0]       \n",
            "                                                                 conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, 4, 4, 36)     144         concatenate_324[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, 4, 4, 36)     0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, 4, 4, 18)     5832        activation_352[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_325 (Concatenate)   (None, 4, 4, 54)     0           concatenate_324[0][0]            \n",
            "                                                                 conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, 4, 4, 54)     216         concatenate_325[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, 4, 4, 54)     0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, 4, 4, 18)     8748        activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_326 (Concatenate)   (None, 4, 4, 72)     0           concatenate_325[0][0]            \n",
            "                                                                 conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, 4, 4, 72)     288         concatenate_326[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, 4, 4, 72)     0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, 4, 4, 18)     11664       activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_327 (Concatenate)   (None, 4, 4, 90)     0           concatenate_326[0][0]            \n",
            "                                                                 conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, 4, 4, 90)     360         concatenate_327[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, 4, 4, 90)     0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, 4, 4, 18)     14580       activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_328 (Concatenate)   (None, 4, 4, 108)    0           concatenate_327[0][0]            \n",
            "                                                                 conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, 4, 4, 108)    432         concatenate_328[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, 4, 4, 108)    0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, 4, 4, 18)     17496       activation_356[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_329 (Concatenate)   (None, 4, 4, 126)    0           concatenate_328[0][0]            \n",
            "                                                                 conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, 4, 4, 126)    504         concatenate_329[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, 4, 4, 126)    0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, 4, 4, 18)     20412       activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_330 (Concatenate)   (None, 4, 4, 144)    0           concatenate_329[0][0]            \n",
            "                                                                 conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, 4, 4, 144)    576         concatenate_330[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, 4, 4, 144)    0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, 4, 4, 18)     23328       activation_358[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_331 (Concatenate)   (None, 4, 4, 162)    0           concatenate_330[0][0]            \n",
            "                                                                 conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, 4, 4, 162)    648         concatenate_331[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, 4, 4, 162)    0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, 4, 4, 18)     26244       activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_332 (Concatenate)   (None, 4, 4, 180)    0           concatenate_331[0][0]            \n",
            "                                                                 conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, 4, 4, 180)    720         concatenate_332[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, 4, 4, 180)    0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, 4, 4, 18)     29160       activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_333 (Concatenate)   (None, 4, 4, 198)    0           concatenate_332[0][0]            \n",
            "                                                                 conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, 4, 4, 198)    792         concatenate_333[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, 4, 4, 198)    0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, 4, 4, 18)     32076       activation_361[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_334 (Concatenate)   (None, 4, 4, 216)    0           concatenate_333[0][0]            \n",
            "                                                                 conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, 4, 4, 216)    864         concatenate_334[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, 4, 4, 216)    0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, 4, 4, 18)     34992       activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_335 (Concatenate)   (None, 4, 4, 234)    0           concatenate_334[0][0]            \n",
            "                                                                 conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, 4, 4, 234)    936         concatenate_335[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, 4, 4, 234)    0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_27 (AveragePo (None, 2, 2, 234)    0           activation_363[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_5 (Flatten)             (None, 936)          0           average_pooling2d_27[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           9370        flatten_5[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 958,492\n",
            "Trainable params: 945,388\n",
            "Non-trainable params: 13,104\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PM27FIFr099w",
        "outputId": "bab68c1c-6292-4725-a7f5-7925f74198ac"
      },
      "source": [
        "print(len(model.layers))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDX0dRC29hpM"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFIlyVky1OR5"
      },
      "source": [
        "aug = ImageDataGenerator(shear_range=0.2,\n",
        "                         zoom_range=0.2,\n",
        "                         height_shift_range=0.1,\n",
        "                         horizontal_flip=True) \n",
        "\n",
        "# determine Loss function and Optimizer\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWfMNQfL91tO",
        "outputId": "d074acb1-7823-43d5-89c9-985c2409a273"
      },
      "source": [
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"models/CNN_CIFR_APR_21_{epoch:04d}.hdf5\", \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=10)\n",
        "\n",
        "\n",
        "res_model = model.fit(\n",
        "                    x = aug.flow(X_train, y_train, batch_size=batch_size,),\n",
        "                    epochs=150,\n",
        "                    verbose=1, \n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks = [cp_callback])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/150\n",
            "1563/1563 [==============================] - 73s 44ms/step - loss: 2.0559 - accuracy: 0.2771 - val_loss: 1.4818 - val_accuracy: 0.4724\n",
            "Epoch 2/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.3637 - accuracy: 0.5087 - val_loss: 1.3150 - val_accuracy: 0.5554\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.0332 - accuracy: 0.6286 - val_loss: 1.2683 - val_accuracy: 0.5775\n",
            "Epoch 4/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.8787 - accuracy: 0.6897 - val_loss: 1.5207 - val_accuracy: 0.5580\n",
            "Epoch 5/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.7662 - accuracy: 0.7294 - val_loss: 1.2011 - val_accuracy: 0.6211\n",
            "Epoch 6/150\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.6816 - accuracy: 0.7630 - val_loss: 0.9039 - val_accuracy: 0.7009\n",
            "Epoch 7/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.6421 - accuracy: 0.7774 - val_loss: 0.7522 - val_accuracy: 0.7519\n",
            "Epoch 8/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.5894 - accuracy: 0.7970 - val_loss: 0.8303 - val_accuracy: 0.7195\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.5542 - accuracy: 0.8095 - val_loss: 0.7475 - val_accuracy: 0.7489\n",
            "Epoch 10/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5222 - accuracy: 0.8192 - val_loss: 0.5490 - val_accuracy: 0.8099\n",
            "\n",
            "Epoch 00010: saving model to models/CNN_CIFR_APR_21_0010.hdf5\n",
            "Epoch 11/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4958 - accuracy: 0.8288 - val_loss: 0.6702 - val_accuracy: 0.7814\n",
            "Epoch 12/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.4779 - accuracy: 0.8363 - val_loss: 0.7194 - val_accuracy: 0.7740\n",
            "Epoch 13/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.4561 - accuracy: 0.8430 - val_loss: 0.7384 - val_accuracy: 0.7725\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4260 - accuracy: 0.8521 - val_loss: 0.5619 - val_accuracy: 0.8110\n",
            "Epoch 15/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.4232 - accuracy: 0.8553 - val_loss: 0.5817 - val_accuracy: 0.8151\n",
            "Epoch 16/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4044 - accuracy: 0.8586 - val_loss: 0.6623 - val_accuracy: 0.7926\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.3934 - accuracy: 0.8630 - val_loss: 0.5560 - val_accuracy: 0.8214\n",
            "Epoch 18/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.3824 - accuracy: 0.8664 - val_loss: 0.5246 - val_accuracy: 0.8287\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3637 - accuracy: 0.8727 - val_loss: 0.8526 - val_accuracy: 0.7577\n",
            "Epoch 20/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3529 - accuracy: 0.8789 - val_loss: 0.4970 - val_accuracy: 0.8354\n",
            "\n",
            "Epoch 00020: saving model to models/CNN_CIFR_APR_21_0020.hdf5\n",
            "Epoch 21/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3473 - accuracy: 0.8799 - val_loss: 0.5231 - val_accuracy: 0.8289\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.3314 - accuracy: 0.8862 - val_loss: 0.4715 - val_accuracy: 0.8472\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3326 - accuracy: 0.8844 - val_loss: 0.4497 - val_accuracy: 0.8522\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3136 - accuracy: 0.8887 - val_loss: 0.4620 - val_accuracy: 0.8558\n",
            "Epoch 25/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.3057 - accuracy: 0.8926 - val_loss: 0.5079 - val_accuracy: 0.8368\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2968 - accuracy: 0.8960 - val_loss: 0.5256 - val_accuracy: 0.8370\n",
            "Epoch 27/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2956 - accuracy: 0.8980 - val_loss: 0.3803 - val_accuracy: 0.8746\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2905 - accuracy: 0.9009 - val_loss: 0.4478 - val_accuracy: 0.8580\n",
            "Epoch 29/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2867 - accuracy: 0.9000 - val_loss: 0.4346 - val_accuracy: 0.8596\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2743 - accuracy: 0.9045 - val_loss: 0.4546 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 00030: saving model to models/CNN_CIFR_APR_21_0030.hdf5\n",
            "Epoch 31/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2683 - accuracy: 0.9080 - val_loss: 0.5228 - val_accuracy: 0.8428\n",
            "Epoch 32/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2710 - accuracy: 0.9055 - val_loss: 0.4431 - val_accuracy: 0.8633\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2574 - accuracy: 0.9113 - val_loss: 0.5754 - val_accuracy: 0.8269\n",
            "Epoch 34/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.2561 - accuracy: 0.9081 - val_loss: 0.3920 - val_accuracy: 0.8749\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.2506 - accuracy: 0.9132 - val_loss: 0.5423 - val_accuracy: 0.8452\n",
            "Epoch 36/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2508 - accuracy: 0.9131 - val_loss: 0.3805 - val_accuracy: 0.8788\n",
            "Epoch 37/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2439 - accuracy: 0.9164 - val_loss: 0.4357 - val_accuracy: 0.8644\n",
            "Epoch 38/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2356 - accuracy: 0.9168 - val_loss: 0.4718 - val_accuracy: 0.8556\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2350 - accuracy: 0.9178 - val_loss: 0.4460 - val_accuracy: 0.8666\n",
            "Epoch 40/150\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2256 - accuracy: 0.9202 - val_loss: 0.4293 - val_accuracy: 0.8715\n",
            "\n",
            "Epoch 00040: saving model to models/CNN_CIFR_APR_21_0040.hdf5\n",
            "Epoch 41/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2238 - accuracy: 0.9221 - val_loss: 0.3896 - val_accuracy: 0.8797\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2212 - accuracy: 0.9235 - val_loss: 0.4427 - val_accuracy: 0.8668\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2175 - accuracy: 0.9235 - val_loss: 0.3910 - val_accuracy: 0.8836\n",
            "Epoch 44/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2178 - accuracy: 0.9247 - val_loss: 0.5024 - val_accuracy: 0.8535\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2113 - accuracy: 0.9260 - val_loss: 0.4228 - val_accuracy: 0.8630\n",
            "Epoch 46/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2051 - accuracy: 0.9284 - val_loss: 0.3894 - val_accuracy: 0.8773\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2042 - accuracy: 0.9309 - val_loss: 0.3584 - val_accuracy: 0.8906\n",
            "Epoch 48/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1979 - accuracy: 0.9295 - val_loss: 0.4130 - val_accuracy: 0.8801\n",
            "Epoch 49/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2004 - accuracy: 0.9297 - val_loss: 0.3788 - val_accuracy: 0.8801\n",
            "Epoch 50/150\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.1926 - accuracy: 0.9327 - val_loss: 0.3910 - val_accuracy: 0.8810\n",
            "\n",
            "Epoch 00050: saving model to models/CNN_CIFR_APR_21_0050.hdf5\n",
            "Epoch 51/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1924 - accuracy: 0.9326 - val_loss: 0.3595 - val_accuracy: 0.8904\n",
            "Epoch 52/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1893 - accuracy: 0.9343 - val_loss: 0.4073 - val_accuracy: 0.8819\n",
            "Epoch 53/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1886 - accuracy: 0.9343 - val_loss: 0.3884 - val_accuracy: 0.8874\n",
            "Epoch 54/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1835 - accuracy: 0.9357 - val_loss: 0.4128 - val_accuracy: 0.8698\n",
            "Epoch 55/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1859 - accuracy: 0.9356 - val_loss: 0.4159 - val_accuracy: 0.8852\n",
            "Epoch 56/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1787 - accuracy: 0.9351 - val_loss: 0.4618 - val_accuracy: 0.8741\n",
            "Epoch 57/150\n",
            "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1783 - accuracy: 0.9356 - val_loss: 0.3833 - val_accuracy: 0.8864\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1774 - accuracy: 0.9395 - val_loss: 0.4322 - val_accuracy: 0.8756\n",
            "Epoch 59/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1746 - accuracy: 0.9386 - val_loss: 0.5668 - val_accuracy: 0.8438\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1712 - accuracy: 0.9403 - val_loss: 0.5007 - val_accuracy: 0.8572\n",
            "\n",
            "Epoch 00060: saving model to models/CNN_CIFR_APR_21_0060.hdf5\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1727 - accuracy: 0.9412 - val_loss: 0.4146 - val_accuracy: 0.8800\n",
            "Epoch 62/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1606 - accuracy: 0.9448 - val_loss: 0.3966 - val_accuracy: 0.8819\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1624 - accuracy: 0.9431 - val_loss: 0.4694 - val_accuracy: 0.8750\n",
            "Epoch 64/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1657 - accuracy: 0.9416 - val_loss: 0.3988 - val_accuracy: 0.8865\n",
            "Epoch 65/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1577 - accuracy: 0.9452 - val_loss: 0.4243 - val_accuracy: 0.8873\n",
            "Epoch 66/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1551 - accuracy: 0.9465 - val_loss: 0.3759 - val_accuracy: 0.8915\n",
            "Epoch 67/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1589 - accuracy: 0.9436 - val_loss: 0.3728 - val_accuracy: 0.8912\n",
            "Epoch 68/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1544 - accuracy: 0.9466 - val_loss: 0.4373 - val_accuracy: 0.8815\n",
            "Epoch 69/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1531 - accuracy: 0.9462 - val_loss: 0.3604 - val_accuracy: 0.8975\n",
            "Epoch 70/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1528 - accuracy: 0.9475 - val_loss: 0.4536 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 00070: saving model to models/CNN_CIFR_APR_21_0070.hdf5\n",
            "Epoch 71/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1522 - accuracy: 0.9464 - val_loss: 0.4337 - val_accuracy: 0.8819\n",
            "Epoch 72/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1503 - accuracy: 0.9469 - val_loss: 0.3924 - val_accuracy: 0.8940\n",
            "Epoch 73/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1411 - accuracy: 0.9512 - val_loss: 0.4700 - val_accuracy: 0.8790\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1460 - accuracy: 0.9487 - val_loss: 0.3794 - val_accuracy: 0.8947\n",
            "Epoch 75/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1416 - accuracy: 0.9499 - val_loss: 0.4935 - val_accuracy: 0.8671\n",
            "Epoch 76/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1380 - accuracy: 0.9512 - val_loss: 0.3925 - val_accuracy: 0.8887\n",
            "Epoch 77/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1455 - accuracy: 0.9503 - val_loss: 0.4475 - val_accuracy: 0.8886\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1444 - accuracy: 0.9488 - val_loss: 0.4721 - val_accuracy: 0.8780\n",
            "Epoch 79/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1383 - accuracy: 0.9532 - val_loss: 0.3739 - val_accuracy: 0.8961\n",
            "Epoch 80/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1349 - accuracy: 0.9513 - val_loss: 0.4277 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 00080: saving model to models/CNN_CIFR_APR_21_0080.hdf5\n",
            "Epoch 81/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1345 - accuracy: 0.9530 - val_loss: 0.4701 - val_accuracy: 0.8802\n",
            "Epoch 82/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1338 - accuracy: 0.9542 - val_loss: 0.4273 - val_accuracy: 0.8848\n",
            "Epoch 83/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1376 - accuracy: 0.9516 - val_loss: 0.4584 - val_accuracy: 0.8809\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1360 - accuracy: 0.9516 - val_loss: 0.3975 - val_accuracy: 0.8937\n",
            "Epoch 85/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1304 - accuracy: 0.9536 - val_loss: 0.3940 - val_accuracy: 0.8953\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1279 - accuracy: 0.9555 - val_loss: 0.4143 - val_accuracy: 0.8899\n",
            "Epoch 87/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1232 - accuracy: 0.9564 - val_loss: 0.5233 - val_accuracy: 0.8780\n",
            "Epoch 88/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1300 - accuracy: 0.9547 - val_loss: 0.3722 - val_accuracy: 0.8982\n",
            "Epoch 89/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1255 - accuracy: 0.9556 - val_loss: 0.3879 - val_accuracy: 0.8980\n",
            "Epoch 90/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1246 - accuracy: 0.9557 - val_loss: 0.4095 - val_accuracy: 0.8980\n",
            "\n",
            "Epoch 00090: saving model to models/CNN_CIFR_APR_21_0090.hdf5\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1215 - accuracy: 0.9573 - val_loss: 0.4667 - val_accuracy: 0.8832\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1265 - accuracy: 0.9553 - val_loss: 0.4134 - val_accuracy: 0.8881\n",
            "Epoch 93/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1178 - accuracy: 0.9585 - val_loss: 0.4407 - val_accuracy: 0.8924\n",
            "Epoch 94/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1252 - accuracy: 0.9555 - val_loss: 0.4126 - val_accuracy: 0.8945\n",
            "Epoch 95/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1240 - accuracy: 0.9578 - val_loss: 0.5021 - val_accuracy: 0.8775\n",
            "Epoch 96/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1123 - accuracy: 0.9608 - val_loss: 0.4373 - val_accuracy: 0.8861\n",
            "Epoch 97/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1188 - accuracy: 0.9590 - val_loss: 0.3692 - val_accuracy: 0.9013\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1124 - accuracy: 0.9609 - val_loss: 0.4346 - val_accuracy: 0.8933\n",
            "Epoch 99/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1223 - accuracy: 0.9584 - val_loss: 0.3783 - val_accuracy: 0.8982\n",
            "Epoch 100/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1120 - accuracy: 0.9611 - val_loss: 0.3999 - val_accuracy: 0.8988\n",
            "\n",
            "Epoch 00100: saving model to models/CNN_CIFR_APR_21_0100.hdf5\n",
            "Epoch 101/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1081 - accuracy: 0.9615 - val_loss: 0.4202 - val_accuracy: 0.8976\n",
            "Epoch 102/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1173 - accuracy: 0.9598 - val_loss: 0.4964 - val_accuracy: 0.8828\n",
            "Epoch 103/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1106 - accuracy: 0.9610 - val_loss: 0.3922 - val_accuracy: 0.9002\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1069 - accuracy: 0.9627 - val_loss: 0.3959 - val_accuracy: 0.8936\n",
            "Epoch 105/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1078 - accuracy: 0.9615 - val_loss: 0.5215 - val_accuracy: 0.8794\n",
            "Epoch 106/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1123 - accuracy: 0.9612 - val_loss: 0.3960 - val_accuracy: 0.9014\n",
            "Epoch 107/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1150 - accuracy: 0.9598 - val_loss: 0.5091 - val_accuracy: 0.8793\n",
            "Epoch 108/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1043 - accuracy: 0.9639 - val_loss: 0.4140 - val_accuracy: 0.8966\n",
            "Epoch 109/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1090 - accuracy: 0.9628 - val_loss: 0.3764 - val_accuracy: 0.8987\n",
            "Epoch 110/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1075 - accuracy: 0.9625 - val_loss: 0.4183 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 00110: saving model to models/CNN_CIFR_APR_21_0110.hdf5\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1094 - accuracy: 0.9617 - val_loss: 0.4139 - val_accuracy: 0.8919\n",
            "Epoch 112/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1040 - accuracy: 0.9642 - val_loss: 0.4082 - val_accuracy: 0.8986\n",
            "Epoch 113/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1005 - accuracy: 0.9640 - val_loss: 0.4627 - val_accuracy: 0.8895\n",
            "Epoch 114/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0984 - accuracy: 0.9657 - val_loss: 0.4565 - val_accuracy: 0.8856\n",
            "Epoch 115/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1029 - accuracy: 0.9643 - val_loss: 0.4881 - val_accuracy: 0.8857\n",
            "Epoch 116/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1068 - accuracy: 0.9624 - val_loss: 0.4593 - val_accuracy: 0.8909\n",
            "Epoch 117/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1031 - accuracy: 0.9639 - val_loss: 0.3854 - val_accuracy: 0.9030\n",
            "Epoch 118/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0920 - accuracy: 0.9669 - val_loss: 0.4358 - val_accuracy: 0.8948\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0980 - accuracy: 0.9661 - val_loss: 0.4369 - val_accuracy: 0.8930\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0976 - accuracy: 0.9659 - val_loss: 0.4985 - val_accuracy: 0.8838\n",
            "\n",
            "Epoch 00120: saving model to models/CNN_CIFR_APR_21_0120.hdf5\n",
            "Epoch 121/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0970 - accuracy: 0.9671 - val_loss: 0.4758 - val_accuracy: 0.8839\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0973 - accuracy: 0.9666 - val_loss: 0.4733 - val_accuracy: 0.8850\n",
            "Epoch 123/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0940 - accuracy: 0.9672 - val_loss: 0.4737 - val_accuracy: 0.8935\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0987 - accuracy: 0.9650 - val_loss: 0.4241 - val_accuracy: 0.9002\n",
            "Epoch 125/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0959 - accuracy: 0.9671 - val_loss: 0.3767 - val_accuracy: 0.9051\n",
            "Epoch 126/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0937 - accuracy: 0.9664 - val_loss: 0.4093 - val_accuracy: 0.9036\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0913 - accuracy: 0.9687 - val_loss: 0.4677 - val_accuracy: 0.8884\n",
            "Epoch 128/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0913 - accuracy: 0.9687 - val_loss: 0.4663 - val_accuracy: 0.8896\n",
            "Epoch 129/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0961 - accuracy: 0.9660 - val_loss: 0.5348 - val_accuracy: 0.8726\n",
            "Epoch 130/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0934 - accuracy: 0.9675 - val_loss: 0.4149 - val_accuracy: 0.8986\n",
            "\n",
            "Epoch 00130: saving model to models/CNN_CIFR_APR_21_0130.hdf5\n",
            "Epoch 131/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0895 - accuracy: 0.9691 - val_loss: 0.4354 - val_accuracy: 0.8897\n",
            "Epoch 132/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0887 - accuracy: 0.9684 - val_loss: 0.4052 - val_accuracy: 0.9012\n",
            "Epoch 133/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0890 - accuracy: 0.9693 - val_loss: 0.4147 - val_accuracy: 0.8941\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0966 - accuracy: 0.9674 - val_loss: 0.3841 - val_accuracy: 0.9030\n",
            "Epoch 135/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0865 - accuracy: 0.9701 - val_loss: 0.4504 - val_accuracy: 0.8951\n",
            "Epoch 136/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0887 - accuracy: 0.9691 - val_loss: 0.4288 - val_accuracy: 0.8986\n",
            "Epoch 137/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0901 - accuracy: 0.9685 - val_loss: 0.4134 - val_accuracy: 0.9014\n",
            "Epoch 138/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0831 - accuracy: 0.9711 - val_loss: 0.4349 - val_accuracy: 0.8948\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0841 - accuracy: 0.9712 - val_loss: 0.3907 - val_accuracy: 0.9019\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0858 - accuracy: 0.9708 - val_loss: 0.4171 - val_accuracy: 0.9001\n",
            "\n",
            "Epoch 00140: saving model to models/CNN_CIFR_APR_21_0140.hdf5\n",
            "Epoch 141/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0846 - accuracy: 0.9700 - val_loss: 0.4477 - val_accuracy: 0.8952\n",
            "Epoch 142/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0903 - accuracy: 0.9689 - val_loss: 0.4104 - val_accuracy: 0.9055\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0849 - accuracy: 0.9711 - val_loss: 0.4430 - val_accuracy: 0.8979\n",
            "Epoch 144/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.4034 - val_accuracy: 0.9084\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0850 - accuracy: 0.9699 - val_loss: 0.4622 - val_accuracy: 0.8938\n",
            "Epoch 146/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0870 - accuracy: 0.9697 - val_loss: 0.3974 - val_accuracy: 0.8989\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0787 - accuracy: 0.9721 - val_loss: 0.4772 - val_accuracy: 0.8939\n",
            "Epoch 148/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0839 - accuracy: 0.9712 - val_loss: 0.3918 - val_accuracy: 0.9041\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0790 - accuracy: 0.9730 - val_loss: 0.4260 - val_accuracy: 0.9013\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0799 - accuracy: 0.9726 - val_loss: 0.4882 - val_accuracy: 0.8944\n",
            "\n",
            "Epoch 00150: saving model to models/CNN_CIFR_APR_21_0150.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFeI1WOj6yLZ",
        "outputId": "76626cc9-1684-4c1f-a746-dec41610e244"
      },
      "source": [
        "# Continue Trainin from 150th epoch + train for 50 more epochs\n",
        "\n",
        "model.load_weights(\"/content/CNN_CIFR_APR_21_0150.hdf5\")\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"models/CNN_CIFR_APR_21_{epoch:04d}.hdf5\", \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    period=10)\n",
        "\n",
        "\n",
        "res_model = model.fit(\n",
        "                    x = aug.flow(X_train, y_train, batch_size=batch_size,),\n",
        "                    epochs=20,\n",
        "                    verbose=1, \n",
        "                    validation_data=(X_test, y_test),\n",
        "                    callbacks = [cp_callback])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 71s 43ms/step - loss: 0.0626 - accuracy: 0.9779 - val_loss: 0.3811 - val_accuracy: 0.9143\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0453 - accuracy: 0.9852 - val_loss: 0.3894 - val_accuracy: 0.9139\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 66s 43ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.3807 - val_accuracy: 0.9155\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0362 - accuracy: 0.9869 - val_loss: 0.3820 - val_accuracy: 0.9192\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0363 - accuracy: 0.9873 - val_loss: 0.3781 - val_accuracy: 0.9206\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0321 - accuracy: 0.9885 - val_loss: 0.3949 - val_accuracy: 0.9164\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0314 - accuracy: 0.9889 - val_loss: 0.3933 - val_accuracy: 0.9170\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.4028 - val_accuracy: 0.9185\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0336 - accuracy: 0.9893 - val_loss: 0.4021 - val_accuracy: 0.9168\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0290 - accuracy: 0.9898 - val_loss: 0.4029 - val_accuracy: 0.9173\n",
            "\n",
            "Epoch 00010: saving model to models/CNN_CIFR_APR_21_0010.hdf5\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0295 - accuracy: 0.9899 - val_loss: 0.3988 - val_accuracy: 0.9176\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0279 - accuracy: 0.9905 - val_loss: 0.4015 - val_accuracy: 0.9204\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0270 - accuracy: 0.9898 - val_loss: 0.4116 - val_accuracy: 0.9191\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0273 - accuracy: 0.9903 - val_loss: 0.4094 - val_accuracy: 0.9182\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0275 - accuracy: 0.9907 - val_loss: 0.4345 - val_accuracy: 0.9153\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0266 - accuracy: 0.9915 - val_loss: 0.4220 - val_accuracy: 0.9180\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.4257 - val_accuracy: 0.9197\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 0.4091 - val_accuracy: 0.9231\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.4164 - val_accuracy: 0.9213\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 0.0247 - accuracy: 0.9910 - val_loss: 0.4300 - val_accuracy: 0.9200\n",
            "\n",
            "Epoch 00020: saving model to models/CNN_CIFR_APR_21_0020.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9RiyBjF1emM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f419ba72-88b3-4b2c-ce9e-ccc6d7dbbb82"
      },
      "source": [
        "# Test the model\n",
        "score = model.evaluate(X_test, y_test, verbose=1)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 11ms/step - loss: 0.4300 - accuracy: 0.9200\n",
            "Test loss: 0.4300319254398346\n",
            "Test accuracy: 0.9200000166893005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6C5YnHED-jt",
        "outputId": "d9fb412a-e517-4bf8-d001-26c7b7cb34ad"
      },
      "source": [
        "# Save the trained weights in to .h5 format\n",
        "model.save_weights(\"DNST_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
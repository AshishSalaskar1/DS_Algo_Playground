{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Call_Backs_Assignment Completed.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "YjCrhKeBhBYF",
        "NSabeFPzemQo"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf0AGnAvhF1m"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from tensorflow.keras.layers import Dense,Input,Activation\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "import random as rn\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.utils import to_categorical\r\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score,roc_auc_score\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, TerminateOnNaN, ReduceLROnPlateau, ModelCheckpoint"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12lhQ0rWfkHE"
      },
      "source": [
        "%load_ext tensorboard\r\n",
        "import datetime"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpqScwA6fm0U"
      },
      "source": [
        "# Clear any logs from previous runs\r\n",
        "!rm -rf ./logs/\r\n",
        "# %tensorboard --logdir logs/fit"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nK5oMqYiqJP"
      },
      "source": [
        "# Hide warnings from Keras\r\n",
        "def warn(*args, **kwargs):\r\n",
        "    pass\r\n",
        "import warnings\r\n",
        "warnings.warn = warn"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P1QsUfhg9j1"
      },
      "source": [
        "# Instructions\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQDRNrY2NCXf"
      },
      "source": [
        "<pre>\n",
        "1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>\n",
        "\n",
        "2. Code the model to classify data like below image\n",
        "\n",
        "<img src='https://i.imgur.com/33ptOFy.png'>\n",
        "\n",
        "3. Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.\n",
        "\n",
        "4. Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
        "\n",
        "5. you have to decay learning based on below conditions \n",
        "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
        "               learning rate by 10%. \n",
        "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
        "        \n",
        "6. If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
        "\n",
        "7. You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
        "\n",
        "8. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "9. use cross entropy as loss function\n",
        "\n",
        "10. Try the architecture params as given below. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w41Y3TFENCXk"
      },
      "source": [
        "<pre>\n",
        "<b>Model-1</b>\n",
        "<pre>\n",
        "1. Use tanh as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-2</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use RandomUniform(0,1) as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-3</b>\n",
        "<pre>\n",
        "1. Use relu as an activation for every layer except output layer.\n",
        "2. use SGD with momentum as optimizer.\n",
        "3. use he_uniform() as initilizer.\n",
        "3. Analyze your output and training process. \n",
        "</pre>\n",
        "</pre>\n",
        "<pre>\n",
        "<b>Model-4</b>\n",
        "<pre>\n",
        "1. Try with any values to get better accuracy/f1 score.  \n",
        "</pre>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjCrhKeBhBYF"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt0_76CrhCL6"
      },
      "source": [
        "data = pd.read_csv(\"data.csv\")\r\n",
        "X = data.iloc[:,:-1].values\r\n",
        "y = data.iloc[:,-1].values"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKnU_F9_i9XV"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=10)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIOKyP6mxPe",
        "outputId": "bb8acc1e-6ca9-47aa-cddd-9b2d8a50a909"
      },
      "source": [
        "y_train = to_categorical(y_train, 2)\r\n",
        "y_test = to_categorical(y_test, 2)\r\n",
        "print(X_train.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(X_test.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14000, 2)\n",
            "(14000, 2)\n",
            "(6000, 2)\n",
            "(6000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSabeFPzemQo"
      },
      "source": [
        "# Callbacks Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAVXUgT8elNV"
      },
      "source": [
        "# Monitor MicroF1 and AUC Score\r\n",
        "class Metrics_Callback(tf.keras.callbacks.Callback):\r\n",
        "  def __init__(self,x_val,y_val):\r\n",
        "    self.x_val = x_val\r\n",
        "    self.y_val = y_val\r\n",
        "\r\n",
        "  def on_train_begin(self, logs={}):\r\n",
        "    self.history = {\"auc_score\":[],\"micro_f1\":[]}\r\n",
        "  \r\n",
        "  def on_epoch_end(self, epoch, logs={}):\r\n",
        "    auc_score = roc_auc_score(self.y_val, model.predict_proba(self.x_val))\r\n",
        "\r\n",
        "    y_true = [0 if x[0]==1.0 else 1 for x in self.y_val]\r\n",
        "    f1_s = f1_score(y_true,self.model.predict_classes(self.x_val), average='micro')\r\n",
        "\r\n",
        "    self.history[\"auc_score\"].append(auc_score)\r\n",
        "    self.history[\"micro_f1\"].append(f1_s)\r\n",
        "\r\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oX74H99erhX"
      },
      "source": [
        "# Change lr on every third epoch\r\n",
        "def schedule(epoch,lr):\r\n",
        "  if epoch % 3 == 0:\r\n",
        "    lr = lr - (lr*.05)\r\n",
        "    return lr\r\n",
        "  return lr"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evjGiFawFY9Q"
      },
      "source": [
        "!mkdir models"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUdSVZQ0eyTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727ff5a2-0973-4936-9013-fd14265ef74e"
      },
      "source": [
        "!rm models/*"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'models/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtdF382_erbW"
      },
      "source": [
        "\r\n",
        "Metrics = Metrics_Callback(X_test,y_test)\r\n",
        "# Stop training is val_accuracy has not increased from last 2 epochs\r\n",
        "EarlyStop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=2,mode='max')\r\n",
        "\r\n",
        "# Stop training if NaN is encountered\r\n",
        "NanStop = TerminateOnNaN()\r\n",
        "\r\n",
        "# Decrease lr by 5% for every 3rd epoch\r\n",
        "LrScheduler = LearningRateScheduler(schedule,verbose=1)\r\n",
        "\r\n",
        "# Decrease lr by 10% => lr*lr(1-0.10)\r\n",
        "LrValAccuracy = ReduceLROnPlateau(monitor='val_accuracy', patience=1, factor= 0.9, mode='max', verbose=0)\r\n",
        "\r\n",
        "#Save model if val_accuracy increases\r\n",
        "filePath = \"models/Model1_weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\r\n",
        "model_checkpoint_callback = ModelCheckpoint(\r\n",
        "    filepath=filePath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb6Dyqi9Mqpb"
      },
      "source": [
        "# !rm -rf logs/*"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mtIzM_jiE2p"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1e5KDxmjt5s"
      },
      "source": [
        "# 1. Use tanh as an activation for every layer except output layer.\r\n",
        "# 2. use SGD with momentum as optimizer.\r\n",
        "# 3. use RandomUniform(0,1) as initilizer.\r\n",
        "# 3. Analyze your output and training process. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOT1Tv0OiGEQ"
      },
      "source": [
        "model = tf.keras.models.Sequential()\r\n",
        "model.add(Input(shape=(2,)))\r\n",
        "model.add(Dense(5,activation='tanh',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model.add(Dense(4,activation='tanh',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model.add(Dense(4,activation='tanh',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model.add(Dense(3,activation='tanh',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model.add(Dense(3,activation='tanh',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model.add(Dense(2,activation=\"softmax\"))\r\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e5L-ky8lcwR"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1Y5FUild0Yn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0311508-d61a-41c9-c97d-e59ccfea45ef"
      },
      "source": [
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\r\n",
        "\r\n",
        "model.fit(X_train,y_train, \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(X_test,y_test), \r\n",
        "          callbacks = [tensorboard_callback, Metrics, EarlyStop, NanStop, LrScheduler, LrValAccuracy, model_checkpoint_callback])"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.09500000141561031.\n",
            "  3/438 [..............................] - ETA: 15s - loss: 0.8104 - accuracy: 0.4878 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_train_batch_end` time: 0.0110s). Check your callbacks.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.7002 - accuracy: 0.5174 - val_loss: 0.6950 - val_accuracy: 0.5013\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0949999988079071.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6914 - accuracy: 0.5282 - val_loss: 0.6859 - val_accuracy: 0.5405\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0949999988079071.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6889 - accuracy: 0.5336 - val_loss: 0.6957 - val_accuracy: 0.5012\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0812250018119812.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6853 - accuracy: 0.5243 - val_loss: 0.6897 - val_accuracy: 0.5327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20e4cb03c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ptEWNpiHvik",
        "outputId": "8fa6a0c3-34e7-4abb-cf8a-df7a7893c0e1"
      },
      "source": [
        "Metrics.history"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc_score': [0.5142775777334787,\n",
              "  0.5143046612142665,\n",
              "  0.528762739930473,\n",
              "  0.5292529370437684],\n",
              " 'micro_f1': [0.5013333333333333,\n",
              "  0.5405,\n",
              "  0.5011666666666666,\n",
              "  0.5326666666666666]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7JgVqL6XDpl"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYRKft0BgJ4k"
      },
      "source": [
        "# Model 2\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBFU9Li_dcvS"
      },
      "source": [
        "# 1. Use relu as an activation for every layer except output layer.\r\n",
        "# 2. use SGD with momentum as optimizer.\r\n",
        "# 3. use RandomUniform(0,1) as initilizer.\r\n",
        "# 3. Analyze your output and training process. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5v89W0Fck5z"
      },
      "source": [
        "model2 = tf.keras.models.Sequential()\r\n",
        "model2.add(Input(shape=(2,)))\r\n",
        "model2.add(Dense(5,activation='relu',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model2.add(Dense(4,activation='relu',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model2.add(Dense(4,activation='relu',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model2.add(Dense(3,activation='relu',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model2.add(Dense(3,activation='relu',kernel_initializer=tf.keras.initializers.random_uniform(0,1)))\r\n",
        "model2.add(Dense(2,activation=\"softmax\"))\r\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWvsBNeMlfw6"
      },
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbbQEsb4hHq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caa09be-584f-4030-fe3e-e58204b2e989"
      },
      "source": [
        "filePath = \"models/Model2_weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\r\n",
        "model_checkpoint_callback = ModelCheckpoint(\r\n",
        "    filepath=filePath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max')\r\n",
        "\r\n",
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\r\n",
        "\r\n",
        "model2.fit(X_train,y_train, \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(X_test,y_test), \r\n",
        "          callbacks = [Metrics, EarlyStop, NanStop, LrScheduler, LrValAccuracy, model_checkpoint_callback, tensorboard_callback])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.09500000141561031.\n",
            "  3/438 [..............................] - ETA: 15s - loss: 0.9888 - accuracy: 0.5365 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_train_batch_end` time: 0.0104s). Check your callbacks.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.7236 - accuracy: 0.4966 - val_loss: 0.6943 - val_accuracy: 0.5012\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0949999988079071.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6973 - accuracy: 0.4961 - val_loss: 0.6942 - val_accuracy: 0.5012\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.08550000190734863.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6966 - accuracy: 0.5005 - val_loss: 0.6982 - val_accuracy: 0.5012\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f20e483e828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDhrj0YfIZqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f8a722-8066-477e-d99c-e9662804835c"
      },
      "source": [
        "Metrics.history"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc_score': [0.5071516222699435, 0.5071516222699435, 0.5071516222699435],\n",
              " 'micro_f1': [0.5011666666666666, 0.5011666666666666, 0.5011666666666666]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMar1X7zHTcQ"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN_-S7LYfYw5"
      },
      "source": [
        "# Model 3\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYfb7Lrsfke5"
      },
      "source": [
        "# 1. Use relu as an activation for every layer except output layer.\r\n",
        "# 2. use SGD with momentum as optimizer.\r\n",
        "# 3. use he_uniform() as initilizer.\r\n",
        "# 3. Analyze your output and training process. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYv8l21lfke7"
      },
      "source": [
        "model3 = tf.keras.models.Sequential()\r\n",
        "model3.add(Input(shape=(2,)))\r\n",
        "model3.add(Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model3.add(Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model3.add(Dense(5,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model3.add(Dense(5,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model3.add(Dense(3,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model3.add(Dense(2,activation=\"softmax\"))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwscI9x5fke9"
      },
      "source": [
        "model3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTP-M97zfke_",
        "outputId": "e5083712-40ef-4439-b5cf-3521646c03ef"
      },
      "source": [
        "filePath = \"models/Model3_weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\r\n",
        "model_checkpoint_callback = ModelCheckpoint(\r\n",
        "    filepath=filePath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max')\r\n",
        "\r\n",
        "\r\n",
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\r\n",
        "\r\n",
        "model3.fit(X_train,y_train, \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(X_test,y_test), \r\n",
        "          callbacks = [Metrics, EarlyStop, NanStop, LrScheduler, LrValAccuracy, model_checkpoint_callback, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.09500000141561031.\n",
            "  3/438 [..............................] - ETA: 15s - loss: 0.7524 - accuracy: 0.3420 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0031s vs `on_train_batch_end` time: 0.0112s). Check your callbacks.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6862 - accuracy: 0.5265 - val_loss: 0.6362 - val_accuracy: 0.6400\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0949999988079071.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6373 - accuracy: 0.6318 - val_loss: 0.6377 - val_accuracy: 0.6540\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0949999988079071.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6369 - accuracy: 0.6412 - val_loss: 0.6516 - val_accuracy: 0.6372\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0812250018119812.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6221 - val_accuracy: 0.6583\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.08122500032186508.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6257 - accuracy: 0.6602 - val_loss: 0.6291 - val_accuracy: 0.6418\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.07310250401496887.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6258 - accuracy: 0.6598 - val_loss: 0.6228 - val_accuracy: 0.6543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07e629e358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1LjS1lrHUZ9",
        "outputId": "50cfea06-f133-4e87-a509-be7b7c6f398b"
      },
      "source": [
        "Metrics.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc_score': [0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722],\n",
              " 'micro_f1': [0.64,\n",
              "  0.654,\n",
              "  0.6371666666666667,\n",
              "  0.6583333333333333,\n",
              "  0.6418333333333334,\n",
              "  0.6543333333333333]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qTxG1p2HUFb"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FZvvahJIeB-"
      },
      "source": [
        "# Model 4\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezOq6eMaIeB-"
      },
      "source": [
        "# 1. Used relu as an activation for every layer except output layer.\r\n",
        "# 2. used Adam optimizer with learning rate = 0.001\r\n",
        "# 3. used he_uniform() as initilizer "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI3OWRIdIeB_"
      },
      "source": [
        "model4 = tf.keras.models.Sequential()\r\n",
        "model4.add(Input(shape=(2,)))\r\n",
        "model4.add(Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model4.add(Dense(10,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model4.add(Dense(5,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model4.add(Dense(5,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model4.add(Dense(3,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform()))\r\n",
        "model4.add(Dense(2,activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9oD62aoIeB_"
      },
      "source": [
        "model4.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001),\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCcSedt9IeCA",
        "outputId": "048a6c08-2ba7-47b0-e12e-156edc17ed84"
      },
      "source": [
        "filePath = \"models/Model4_weights.{epoch:02d}-{val_loss:.2f}.hdf5\"\r\n",
        "model_checkpoint_callback = ModelCheckpoint(\r\n",
        "    filepath=filePath,\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max')\r\n",
        "\r\n",
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)\r\n",
        "\r\n",
        "model4.fit(X_train,y_train, \r\n",
        "          epochs=10,\r\n",
        "          validation_data=(X_test,y_test), \r\n",
        "          callbacks = [Metrics, EarlyStop, NanStop, LrScheduler, LrValAccuracy, model_checkpoint_callback, tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0009500000451225787.\n",
            "  3/438 [..............................] - ETA: 18s - loss: 0.7060 - accuracy: 0.5417 WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0037s vs `on_train_batch_end` time: 0.0131s). Check your callbacks.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6840 - accuracy: 0.5552 - val_loss: 0.6581 - val_accuracy: 0.6200\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0009500000160187483.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6484 - accuracy: 0.6291 - val_loss: 0.6249 - val_accuracy: 0.6547\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0009500000160187483.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6178 - accuracy: 0.6638 - val_loss: 0.6134 - val_accuracy: 0.6627\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0009025000152178108.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6033 - accuracy: 0.6771 - val_loss: 0.6116 - val_accuracy: 0.6638\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009025000035762787.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6056 - accuracy: 0.6730 - val_loss: 0.6107 - val_accuracy: 0.6660\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0009025000035762787.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.5978 - accuracy: 0.6720 - val_loss: 0.6121 - val_accuracy: 0.6680\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0008573750033974648.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.5991 - accuracy: 0.6731 - val_loss: 0.6098 - val_accuracy: 0.6653\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0007716374821029603.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.5981 - accuracy: 0.6741 - val_loss: 0.6115 - val_accuracy: 0.6682\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0007716374821029603.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.6009 - accuracy: 0.6707 - val_loss: 0.6077 - val_accuracy: 0.6692\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0007330556079978123.\n",
            "438/438 [==============================] - 2s 4ms/step - loss: 0.5997 - accuracy: 0.6688 - val_loss: 0.6078 - val_accuracy: 0.6683\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f07f1d148d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pwq0YUxIeCB",
        "outputId": "268ed803-975c-49f4-9d9f-a73a71a14aa6"
      },
      "source": [
        "Metrics.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc_score': [0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722,\n",
              "  0.4961677846912722],\n",
              " 'micro_f1': [0.62,\n",
              "  0.6546666666666666,\n",
              "  0.6626666666666666,\n",
              "  0.6638333333333334,\n",
              "  0.666,\n",
              "  0.668,\n",
              "  0.6653333333333333,\n",
              "  0.6681666666666667,\n",
              "  0.6691666666666667,\n",
              "  0.6683333333333333]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvbl9Zn1IeCB"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}
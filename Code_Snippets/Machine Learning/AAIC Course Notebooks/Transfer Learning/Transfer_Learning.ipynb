{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Transfer Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PaSWZB6GcPJY"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0zs3TflcAEr"
      },
      "source": [
        "<pre>\n",
        "1. Download all the data in this folder https://drive.google.com/open?id=1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu. it contains two file both images and labels. The label file list the images and their categories in the following format:\n",
        "            <b>path/to/the/image.tif,category</b>\n",
        "            \n",
        "    where the categories are numbered 0 to 15, in the following order:\n",
        "\n",
        "    <b>0 letter\n",
        "    1 form\n",
        "    2 email\n",
        "    3 handwritten\n",
        "    4 advertisement\n",
        "    5 scientific report\n",
        "    6 scientific publication\n",
        "    7 specification\n",
        "    8 file folder\n",
        "    9 news article\n",
        "    10 budget\n",
        "    11 invoice\n",
        "    12 presentation\n",
        "    13 questionnaire\n",
        "    14 resume\n",
        "    15 memo</b>\n",
        "    \n",
        "2. On this image data, you have to train 3 types of models as given below. You have to split the data into Train and Validation data.\n",
        "\n",
        "3. Try not to load all the images into memory, use the gernarators that we have given the reference notebooks to load the batch of images only during the train data.\n",
        "or you can use this method also\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-imagedatagenerator-with-flow-from-dataframe-8bd5776e45c1</a>\n",
        "\n",
        "<a href='https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c'>https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c</a>\n",
        "\n",
        "\n",
        "4. You are free to choose Learning rate, optimizer, loss function, image augmentation, any hyperparameters. but you have to use the same architechture what we are asking below. \n",
        "\n",
        "5. Use tensorboard for every model and analyse your gradients. (you need to upload the screenshots for each model for evaluation)\n",
        "\n",
        "Note: fit_genarator() method will have problems with the tensorboard histograms, try to debug it, if you could not do use histgrams=0 i.e don't include histograms, check the documentation of tensorboard for more information. \n",
        "\n",
        "6. You can check about Transfer Learning in this link - <a href='https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html'>https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html</a>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZXpEZtJcAEu"
      },
      "source": [
        "### Model-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF12MYu1cAEy"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights. \n",
        "2. After VGG-16 network without FC layers, add a new Conv block ( 1 Conv layer and 1 Maxpooling ), 2 FC layers and a output layer to classify 16 classes. You are free to choose any hyperparameters/parameters of conv block, FC layers, output layer. \n",
        "3. Final architecture will be <b>INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer</b>\n",
        "4. Train only new Conv block, FC layers, output layer. Don't train the VGG-16 network. \n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0UlsaOcAE1"
      },
      "source": [
        "### Model-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNXN3EXFcAE5"
      },
      "source": [
        "<pre>\n",
        "1. Use <a href='https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16'>VGG-16</a> pretrained network without Fully Connected layers and initilize all the weights with Imagenet trained weights.\n",
        "2. After VGG-16 network without FC layers, don't use FC layers, use conv layers only as Fully connected layer. any FC layer can be converted to a CONV layer. This conversion will reduce the No of Trainable parameters in FC layers. For example, an FC layer with K=4096 that is looking at some input volume of size 7×7×512 can be equivalently expressed as a CONV layer with F=7,P=0,S=1,K=4096. In other words, we are setting the filter size to be exactly the size of the input volume, and hence the output will simply be 1×1×4096 since only a single depth column “fits” across the input volume, giving identical result as the initial FC layer. You can refer <a href='http://cs231n.github.io/convolutional-networks/#convert'>this</a> link to better understanding of using Conv layer in place of fully connected layers.\n",
        "3. Final architecture will be VGG-16 without FC layers(without top), 2 Conv layers identical to FC layers, 1 output layer for 16 class classification. <b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>\n",
        "3. Train only last 2 Conv layers identical to FC layers, 1 output layer. Don't train the VGG-16 network. \n",
        "</pre>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amKbfojfcAE-"
      },
      "source": [
        "## Model-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AULF-PcAFC"
      },
      "source": [
        "<pre>\n",
        "1. Use same network as Model-2 '<b>INPUT --> VGG-16 without Top layers(FC) --> 2 Conv Layers identical to FC --> Output Layer</b>' and train only Last 6 Layers of VGG-16 network, 2 Conv layers identical to FC layers, 1 output layer.\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYfd9Ii8WHMy"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import shutil\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras_preprocessing.image import ImageDataGenerator\r\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import regularizers, optimizers\r\n",
        "\r\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ax14mKGTWHrR",
        "outputId": "a009b34c-4301-4f2f-fef4-1e1bd37ff5b4"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iYG1xLFV8vq"
      },
      "source": [
        "# Get the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0JvLVyiV-4-"
      },
      "source": [
        "!gdown --id 1Z4TyI7FcFVEx8qdl4jO9qxvxaqLSqoEu -q"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ski7jNdAbzQ9"
      },
      "source": [
        "!mkdir dataset"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Up8EleXV-17"
      },
      "source": [
        "!unrar e \"/content/rvl-cdip.rar\" \"dataset/\""
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "13pjucaUSqQ4",
        "outputId": "e9dbdacb-b408-41e0-f29d-fdad6641f960"
      },
      "source": [
        "shutil.move(\"./dataset/labels_final.csv\",\"./\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./labels_final.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaSWZB6GcPJY"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "m2-EuskgV-po",
        "outputId": "b034da56-d28e-40ab-c5b0-830ec59b4247"
      },
      "source": [
        "datadf = pd.read_csv(\"labels_final.csv\")\r\n",
        "datadf.tail(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47995</th>\n",
              "      <td>imagesk/k/q/l/kql82f00/tob07414.87.tif</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47996</th>\n",
              "      <td>imagesi/i/r/r/irr80c00/2084343690_3692.tif</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47997</th>\n",
              "      <td>imagesa/a/z/h/azh32d00/2063887153_7176.tif</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47998</th>\n",
              "      <td>imagesg/g/p/d/gpd45f00/0060075263.tif</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47999</th>\n",
              "      <td>imagesr/r/o/l/rol45d00/2064701657.tif</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             path  label\n",
              "47995      imagesk/k/q/l/kql82f00/tob07414.87.tif     10\n",
              "47996  imagesi/i/r/r/irr80c00/2084343690_3692.tif     12\n",
              "47997  imagesa/a/z/h/azh32d00/2063887153_7176.tif      6\n",
              "47998       imagesg/g/p/d/gpd45f00/0060075263.tif      8\n",
              "47999       imagesr/r/o/l/rol45d00/2064701657.tif      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQQkO_T1fOkn"
      },
      "source": [
        "datadf[\"file_name\"] = datadf[\"path\"].apply(lambda x: x.split(\"/\")[-1]) \r\n",
        "datadf[\"label\"] = datadf[\"label\"].apply(lambda x: str(x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VvYSeMN8gJK5",
        "outputId": "1e4aa029-cada-4f39-9c32-b597e6d04929"
      },
      "source": [
        "datadf.head(3)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>file_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>imagesv/v/o/h/voh71d00/509132755+-2755.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>509132755+-2755.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>imagesl/l/x/t/lxt19d00/502213303.tif</td>\n",
              "      <td>3</td>\n",
              "      <td>502213303.tif</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>imagesx/x/e/d/xed05a00/2075325674.tif</td>\n",
              "      <td>2</td>\n",
              "      <td>2075325674.tif</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         path label            file_name\n",
              "0  imagesv/v/o/h/voh71d00/509132755+-2755.tif     3  509132755+-2755.tif\n",
              "1        imagesl/l/x/t/lxt19d00/502213303.tif     3        502213303.tif\n",
              "2       imagesx/x/e/d/xed05a00/2075325674.tif     2       2075325674.tif"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qad84DtgV-JW"
      },
      "source": [
        "# im = Image.open('dataset/2084343690_3692.tif').convert('RGB')\r\n",
        "# print(im)\r\n",
        "# im = im.resize((156,256))\r\n",
        "# im.size\r\n",
        "# # im"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQTpsuxydLvX"
      },
      "source": [
        "train_df, val_df = train_test_split(datadf,test_size=0.3)\r\n",
        "datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIGnyGVieIXU",
        "outputId": "f0f35e7a-7c19-49ee-ce2b-e4a437e9b662"
      },
      "source": [
        "train_generator=datagen.flow_from_dataframe(\r\n",
        "  dataframe=train_df,\r\n",
        "  directory=\"./dataset/\",\r\n",
        "  x_col=\"file_name\",\r\n",
        "  y_col=\"label\",\r\n",
        "  batch_size=32,\r\n",
        "  seed=42,\r\n",
        "  shuffle=True,\r\n",
        "  class_mode=\"categorical\",\r\n",
        "  target_size=(156,256))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 33600 validated image filenames belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k03YYlvceO-U",
        "outputId": "0a36ca18-c3ad-40bc-ccf7-39091f92999c"
      },
      "source": [
        "val_generator=datagen.flow_from_dataframe(\r\n",
        "  dataframe=val_df,\r\n",
        "  directory=\"./dataset/\",\r\n",
        "  x_col=\"file_name\",\r\n",
        "  y_col=\"label\",\r\n",
        "  batch_size=32,\r\n",
        "  seed=42,\r\n",
        "  shuffle=True,\r\n",
        "  class_mode=\"categorical\",\r\n",
        "  target_size=(156,256))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 14400 validated image filenames belonging to 16 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwpyczBlhPio",
        "outputId": "d0cc23c2-ac93-42fd-b5df-1fa7845d6fd3"
      },
      "source": [
        "print(train_generator.n)\r\n",
        "print(train_generator.batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33600\n",
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o4tn7J0hj-j"
      },
      "source": [
        "# Model 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5-29YQoo13O"
      },
      "source": [
        "INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1okINnWmis8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676df385-8bc2-4962-9c13-420dfda4f921"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\r\n",
        "import keras\r\n",
        "from tensorflow.keras.layers import Dense,Input,Conv2D,MaxPool2D,Activation,Dropout,Flatten\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "import datetime\r\n",
        "%load_ext tensorboard\r\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3qbbtmdfNj3"
      },
      "source": [
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx4Uf6drheBd"
      },
      "source": [
        "base_model = VGG16(\r\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\r\n",
        "    input_shape=(156, 256, 3),\r\n",
        "    include_top=False)  \r\n",
        "base_model.trainable = False"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA0LC3a5nzKJ"
      },
      "source": [
        "inputs = keras.Input(shape=(156, 256, 3))\r\n",
        "\r\n",
        "x = base_model(inputs, training=False)\r\n",
        "\r\n",
        "Conv1 = Conv2D(filters=64,kernel_size=(3,3),padding='same',\r\n",
        "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='Conv1')(x)\r\n",
        "\r\n",
        "Pool1 = MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same',name='Pool1')(Conv1)\r\n",
        "\r\n",
        "#Flatten\r\n",
        "flatten = Flatten(data_format='channels_last',name='Flatten')(Pool1)\r\n",
        "\r\n",
        "FC1 = Dense(units=400,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=32),name='FC1')(flatten)\r\n",
        "\r\n",
        "FC2 = Dense(units=200,activation='relu',kernel_initializer=tf.keras.initializers.glorot_normal(seed=33),name='FC2')(FC1)\r\n",
        "\r\n",
        "outputs = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(FC2)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__WBL3_HqVlm"
      },
      "source": [
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdrXKCQznEy2"
      },
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\r\n",
        "              loss=\"categorical_crossentropy\",\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRIihuuhqxO8",
        "outputId": "9ca42f99-5a3f-4592-902e-4c58413bd68e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_13 (InputLayer)        [(None, 156, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 4, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "Conv1 (Conv2D)               (None, 4, 8, 64)          294976    \n",
            "_________________________________________________________________\n",
            "Pool1 (MaxPooling2D)         (None, 2, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "FC1 (Dense)                  (None, 400)               205200    \n",
            "_________________________________________________________________\n",
            "FC2 (Dense)                  (None, 200)               80200     \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 16)                3216      \n",
            "=================================================================\n",
            "Total params: 15,298,280\n",
            "Trainable params: 583,592\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDLjlbmdnkU3",
        "outputId": "3dcd3ef6-0d7d-4597-8708-5418a6f8717c"
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size  \r\n",
        "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size  \r\n",
        "\r\n",
        "model.fit_generator(generator=train_generator,  \r\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,  \r\n",
        "                    validation_data=val_generator,  \r\n",
        "                    validation_steps=STEP_SIZE_VALID,  \r\n",
        "                    epochs=10,\r\n",
        "                    callbacks = [tensorboard_callback])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 191s 182ms/step - loss: 1.7084 - accuracy: 0.4600 - val_loss: 1.2045 - val_accuracy: 0.6348\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 181s 172ms/step - loss: 1.0845 - accuracy: 0.6658 - val_loss: 1.1227 - val_accuracy: 0.6555\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.9254 - accuracy: 0.7135 - val_loss: 1.0347 - val_accuracy: 0.6892\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 178s 170ms/step - loss: 0.8122 - accuracy: 0.7448 - val_loss: 1.0269 - val_accuracy: 0.6981\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 177s 168ms/step - loss: 0.7240 - accuracy: 0.7741 - val_loss: 1.1051 - val_accuracy: 0.6822\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.6367 - accuracy: 0.7938 - val_loss: 1.0458 - val_accuracy: 0.6976\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 176s 168ms/step - loss: 0.5584 - accuracy: 0.8206 - val_loss: 1.0648 - val_accuracy: 0.7061\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 177s 169ms/step - loss: 0.4869 - accuracy: 0.8404 - val_loss: 1.1052 - val_accuracy: 0.7090\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 177s 169ms/step - loss: 0.4232 - accuracy: 0.8637 - val_loss: 1.1718 - val_accuracy: 0.7073\n",
            "Epoch 10/10\n",
            "1050/1050 [==============================] - 178s 170ms/step - loss: 0.3635 - accuracy: 0.8813 - val_loss: 1.2640 - val_accuracy: 0.7006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee7c14c4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar_d5oaJjPOj"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c59Eej-QdrQl"
      },
      "source": [
        "# Model 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDbQiMZxdrQm"
      },
      "source": [
        "INPUT --> VGG-16 without Top layers(FC) --> Conv Layer --> Maxpool Layer --> 2 FC layers --> Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27zIFpDcdrQn"
      },
      "source": [
        "base_model = VGG16(\r\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\r\n",
        "    input_shape=(156, 256, 3),\r\n",
        "    include_top=False)  \r\n",
        "base_model.trainable = False"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTgmUS1M4qA3"
      },
      "source": [
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJNRSZfBdrQo"
      },
      "source": [
        "inputs = keras.Input(shape=(156, 256, 3))\r\n",
        "\r\n",
        "x = base_model(inputs, training=False)\r\n",
        "\r\n",
        "\r\n",
        "ConvFC1 = Conv2D(filters=400,kernel_size=(4,8),padding='valid',strides=(1,1),\r\n",
        "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='ConvFC1')(x)\r\n",
        "\r\n",
        "ConvFC2 = Conv2D(filters=200,kernel_size=(1,1),padding='valid',strides=(1,1),\r\n",
        "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='ConvFC2')(ConvFC1)\r\n",
        "\r\n",
        "#Train Params : 200*16 = 3200 + 16 (Bias weights) = 3216 params\r\n",
        "flatten = Flatten(data_format='channels_last',name='Flatten')(ConvFC2)\r\n",
        "\r\n",
        "outputs = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(flatten)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHZMM7HddrQp"
      },
      "source": [
        "model2 = keras.Model(inputs, outputs)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZsi-lIGdrQp"
      },
      "source": [
        "model2.compile(optimizer=keras.optimizers.Adam(),\r\n",
        "              loss=\"categorical_crossentropy\",\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rUI_ZT3drQq",
        "outputId": "28c0ad5b-c061-4518-ffd3-395c3ef98649"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 156, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 4, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "ConvFC1 (Conv2D)             (None, 1, 1, 400)         6554000   \n",
            "_________________________________________________________________\n",
            "ConvFC2 (Conv2D)             (None, 1, 1, 200)         80200     \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 16)                3216      \n",
            "=================================================================\n",
            "Total params: 21,352,104\n",
            "Trainable params: 6,637,416\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlfLekAxdrQr",
        "outputId": "5e651328-6ba3-4061-edb8-b6f069a492ae"
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size  \r\n",
        "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size  \r\n",
        "model2.fit_generator(generator=train_generator,  \r\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,  \r\n",
        "                    validation_data=val_generator,  \r\n",
        "                    validation_steps=STEP_SIZE_VALID,  \r\n",
        "                    epochs=10,\r\n",
        "                     callbacks=[tensorboard_callback])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 181s 172ms/step - loss: 1.7048 - accuracy: 0.4965 - val_loss: 1.1781 - val_accuracy: 0.6454\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 181s 172ms/step - loss: 1.0498 - accuracy: 0.6784 - val_loss: 1.0822 - val_accuracy: 0.6787\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 178s 170ms/step - loss: 0.8953 - accuracy: 0.7242 - val_loss: 0.9871 - val_accuracy: 0.7110\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 182s 173ms/step - loss: 0.7747 - accuracy: 0.7621 - val_loss: 0.9891 - val_accuracy: 0.7157\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 182s 174ms/step - loss: 0.6844 - accuracy: 0.7874 - val_loss: 1.0174 - val_accuracy: 0.7072\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 182s 173ms/step - loss: 0.6035 - accuracy: 0.8092 - val_loss: 1.0656 - val_accuracy: 0.7089\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 182s 174ms/step - loss: 0.5421 - accuracy: 0.8278 - val_loss: 1.0484 - val_accuracy: 0.7247\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 182s 173ms/step - loss: 0.4730 - accuracy: 0.8494 - val_loss: 1.0757 - val_accuracy: 0.7199\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 181s 173ms/step - loss: 0.4368 - accuracy: 0.8607 - val_loss: 1.1674 - val_accuracy: 0.7105\n",
            "Epoch 10/10\n",
            "1050/1050 [==============================] - 182s 173ms/step - loss: 0.3912 - accuracy: 0.8737 - val_loss: 1.3354 - val_accuracy: 0.6874\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee5a4659b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDscDEi2I3RY"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZrKC1dpUokV"
      },
      "source": [
        "#Model 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x2tqC4tKCnl"
      },
      "source": [
        "!rm -rf logs/*\r\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1LUwEz0nplP"
      },
      "source": [
        "base_model = VGG16(\r\n",
        "    weights='imagenet',  # Load weights pre-trained on ImageNet.\r\n",
        "    input_shape=(156, 256, 3),\r\n",
        "    include_top=False)  \r\n",
        "base_model.trainable = False"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyRFWKOtaXhw",
        "outputId": "33f60deb-bed7-4cc8-9364-4b56a93c1283"
      },
      "source": [
        "last_6_layers = base_model.layers[-6:]\r\n",
        "for layer in last_6_layers:\r\n",
        "  layer.trainable = True\r\n",
        "\r\n",
        "for idx, layer in enumerate(base_model.layers):\r\n",
        "  print(\"Layer %d Trainaible : %s\"%(idx+1, layer.trainable))\r\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer 1 Trainaible : False\n",
            "Layer 2 Trainaible : False\n",
            "Layer 3 Trainaible : False\n",
            "Layer 4 Trainaible : False\n",
            "Layer 5 Trainaible : False\n",
            "Layer 6 Trainaible : False\n",
            "Layer 7 Trainaible : False\n",
            "Layer 8 Trainaible : False\n",
            "Layer 9 Trainaible : False\n",
            "Layer 10 Trainaible : False\n",
            "Layer 11 Trainaible : False\n",
            "Layer 12 Trainaible : False\n",
            "Layer 13 Trainaible : False\n",
            "Layer 14 Trainaible : True\n",
            "Layer 15 Trainaible : True\n",
            "Layer 16 Trainaible : True\n",
            "Layer 17 Trainaible : True\n",
            "Layer 18 Trainaible : True\n",
            "Layer 19 Trainaible : True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d2ARr-PUoTf"
      },
      "source": [
        "inputs = keras.Input(shape=(156, 256, 3))\r\n",
        "\r\n",
        "x = base_model(inputs, training=False)\r\n",
        "\r\n",
        "ConvFC1 = Conv2D(filters=400,kernel_size=(4,8),padding='valid',strides=(1,1),\r\n",
        "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='ConvFC1')(x)\r\n",
        "\r\n",
        "ConvFC2 = Conv2D(filters=200,kernel_size=(1,1),padding='valid',strides=(1,1),\r\n",
        "              activation='relu',kernel_initializer=tf.keras.initializers.he_normal(seed=0),name='ConvFC2')(ConvFC1)\r\n",
        "\r\n",
        "flatten = Flatten(data_format='channels_last',name='Flatten')(ConvFC2)\r\n",
        "\r\n",
        "outputs = Dense(units=16,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_normal(seed=3),name='Output')(flatten)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAwAXjuuUoRB"
      },
      "source": [
        "model3 = keras.Model(inputs, outputs)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg-NhyyNyln4"
      },
      "source": [
        "model3.compile(optimizer=keras.optimizers.Adam(),\r\n",
        "              loss=\"categorical_crossentropy\",\r\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXzVMQyJflUE",
        "outputId": "4d9b9aee-24dc-4afd-b1fc-58a6b9989da7"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_21 (InputLayer)        [(None, 156, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "vgg16 (Functional)           (None, 4, 8, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "ConvFC1 (Conv2D)             (None, 1, 1, 400)         6554000   \n",
            "_________________________________________________________________\n",
            "ConvFC2 (Conv2D)             (None, 1, 1, 200)         80200     \n",
            "_________________________________________________________________\n",
            "Flatten (Flatten)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "Output (Dense)               (None, 16)                3216      \n",
            "=================================================================\n",
            "Total params: 21,352,104\n",
            "Trainable params: 6,637,416\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E7jzD8TflQ6",
        "outputId": "0914b492-367c-4908-b7de-f01ec3525376"
      },
      "source": [
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size  \r\n",
        "STEP_SIZE_VALID=val_generator.n//val_generator.batch_size  \r\n",
        "model3.fit_generator(generator=train_generator,  \r\n",
        "                    steps_per_epoch=STEP_SIZE_TRAIN,  \r\n",
        "                    validation_data=val_generator,  \r\n",
        "                    validation_steps=STEP_SIZE_VALID,  \r\n",
        "                    epochs=10,\r\n",
        "                     callbacks=[tensorboard_callback])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 175s 166ms/step - loss: 1.6905 - accuracy: 0.4921 - val_loss: 1.1690 - val_accuracy: 0.6485\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 178s 170ms/step - loss: 1.0465 - accuracy: 0.6801 - val_loss: 1.0734 - val_accuracy: 0.6781\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.8770 - accuracy: 0.7304 - val_loss: 1.0044 - val_accuracy: 0.7050\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.7709 - accuracy: 0.7605 - val_loss: 1.0486 - val_accuracy: 0.6879\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.6742 - accuracy: 0.7867 - val_loss: 1.0038 - val_accuracy: 0.7107\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 177s 169ms/step - loss: 0.6090 - accuracy: 0.8066 - val_loss: 1.0802 - val_accuracy: 0.6957\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 177s 169ms/step - loss: 0.5520 - accuracy: 0.8235 - val_loss: 1.0356 - val_accuracy: 0.7145\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 178s 170ms/step - loss: 0.4993 - accuracy: 0.8373 - val_loss: 1.1582 - val_accuracy: 0.7101\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 178s 169ms/step - loss: 0.4343 - accuracy: 0.8619 - val_loss: 1.3375 - val_accuracy: 0.6953\n",
            "Epoch 10/10\n",
            "1050/1050 [==============================] - 177s 169ms/step - loss: 0.4023 - accuracy: 0.8715 - val_loss: 1.2258 - val_accuracy: 0.7108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fee5a1c0ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XzwqJZbflOh"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeZlRHcvflMD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc-BUNpsflGz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKrifMk_flEN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}